<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>[Paper Reading] A Survey on Efficient Inference for Large Language Models | GuMorming</title><meta name="author" content="GuMorming,gumorming@163.com"><meta name="copyright" content="GuMorming"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Paper Source: A Survey on Efficient Inference for Large Language Models  PRELIMINARIES Transformer-Styles LLMs 主流LLM是基于Transformer架构设计的，典型的Transformer架构模型由数个堆叠的（stacked）Transformer Block 组成。  Transfo">
<meta property="og:type" content="article">
<meta property="og:title" content="[Paper Reading] A Survey on Efficient Inference for Large Language Models">
<meta property="og:url" content="https://gumorming.github.io/article/b9645bc9/">
<meta property="og:site_name" content="GuMorming">
<meta property="og:description" content="Paper Source: A Survey on Efficient Inference for Large Language Models  PRELIMINARIES Transformer-Styles LLMs 主流LLM是基于Transformer架构设计的，典型的Transformer架构模型由数个堆叠的（stacked）Transformer Block 组成。  Transfo">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://static.gumorming.cn/article/085dcf98b9e5a23d8ac570261a77058b.png">
<meta property="article:published_time" content="2024-07-19T02:16:40.000Z">
<meta property="article:modified_time" content="2024-09-29T06:31:36.915Z">
<meta property="article:author" content="GuMorming">
<meta property="article:tag" content="Survey">
<meta property="article:tag" content="LLM">
<meta property="article:tag" content="Inference">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://static.gumorming.cn/article/085dcf98b9e5a23d8ac570261a77058b.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://gumorming.github.io/article/b9645bc9/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?https://hm.baidu.com/hm.js?50985a904c42d9eb961b2fd23854d46f";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'mediumZoom',
  Snackbar: {"chs_to_cht":"你已切换为繁体中文","cht_to_chs":"你已切换为简体中文","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-right"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '[Paper Reading] A Survey on Efficient Inference for Large Language Models',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-09-29 14:31:36'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/assets/css/gumorming.css?2"><meta name="generator" content="Hexo 7.3.0"></head><body><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><div class="loading-img" style="background-image:url(/img/Runy.GIF);background-repeat: no-repeat;background-position:center;"></div><div class="loading-image-dot"></div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = 'auto'
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load',() => { preloader.endLoading() })

  if (true) {
    document.addEventListener('pjax:send', () => { preloader.initLoading() })
    document.addEventListener('pjax:complete', () => { preloader.endLoading() })
  }
})()</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/Runy.GIF" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">21</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">30</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-timeline"></i><span> 时间线</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://static.gumorming.cn/article/085dcf98b9e5a23d8ac570261a77058b.png')"><nav id="nav"><span id="blog-info"><a href="/" title="GuMorming"><span class="site-name">GuMorming</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-timeline"></i><span> 时间线</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">[Paper Reading] A Survey on Efficient Inference for Large Language Models</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-07-19T02:16:40.000Z" title="发表于 2024-07-19 10:16:40">2024-07-19</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-09-29T06:31:36.915Z" title="更新于 2024-09-29 14:31:36">2024-09-29</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Paper-Reading/">Paper Reading</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">3.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>12分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="[Paper Reading] A Survey on Efficient Inference for Large Language Models"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote>
<p>Paper Source: <a target="_blank" rel="noopener external nofollow noreferrer" href="https://arxiv.org/abs/2404.14294">A Survey on Efficient Inference for Large Language Models</a></p>
</blockquote>
<h2 id="PRELIMINARIES">PRELIMINARIES</h2>
<h3 id="Transformer-Styles-LLMs">Transformer-Styles LLMs</h3>
<p>主流LLM是基于<strong>Transformer</strong>架构设计的，典型的<strong>Transformer</strong>架构模型由数个<strong>堆叠的</strong>（<strong>stacked</strong>）<strong>Transformer Block</strong><br>
组成。</p>
<blockquote>
<p><code>Transformer Block</code>：</p>
<ul>
<li>Attention-Linear(generate matrix Q, K, V)</li>
<li><strong>Multi-Head Self-Attention</strong>（MHSA）</li>
<li>Feed Forward Network（FFN）</li>
<li>Layer Norm</li>
</ul>
</blockquote>
<p>每个 Transformer Block 接收前一个 Transformer Block 的输出特征，并将其作为输入，并将特征串行送进每个子模块中，最后输出。</p>
<blockquote>
<p>特别的，在第一个 Transformer Block 前，需要用一个 <strong>tokenizer</strong> 将输入语句（prompts）转化为 token 序列，紧接 word embedding<br>
及 positional embedding 层将 token 序列转化为输入特征。</p>
</blockquote>
<p>Transformer架构的<strong>核心</strong>是<strong>自注意力机制</strong><br>
，这一机制在多头自注意力模块（MHSA）中使用。自注意力机制可以让模型在不考虑距离的情况下识别不同输入部分的重要性,也因此可以得到输入语句的长距离依赖及句子内部的复杂关系。</p>
<blockquote>
<p><strong>首先</strong>，MHSA模块对输入进行线性变换得到 Q, K, V向量，如(1):</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><msub><mi>Q</mi><mi>i</mi></msub><mo>=</mo><mi>X</mi><msup><mi>W</mi><msub><mi>Q</mi><mi>i</mi></msub></msup><mo separator="true">,</mo><msub><mi>K</mi><mi>i</mi></msub><mo>=</mo><mi>X</mi><msup><mi>W</mi><msub><mi>K</mi><mi>i</mi></msub></msup><mo separator="true">,</mo><msub><mi>V</mi><mi>i</mi></msub><mo>=</mo><mi>X</mi><msup><mi>W</mi><msub><mi>V</mi><mi>i</mi></msub></msup></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(1)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">Q_i = XW^{Q_i}, K_i = XW^{K_i}, V_i = XW^{V_i} \tag{1}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0858em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0858em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8913em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.2222em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="tag"><span class="strut" style="height:1.1413em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">1</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>=</mo><mo stretchy="false">[</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">X = [x_1,x_2,\dots,x_n]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span>为输入特征, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><msub><mi>Q</mi><mi>i</mi></msub></msup><mo separator="true">,</mo><msup><mi>W</mi><msub><mi>K</mi><mi>i</mi></msub></msup><mo separator="true">,</mo><msup><mi>W</mi><msub><mi>V</mi><mi>i</mi></msub></msup></mrow><annotation encoding="application/x-tex">W^{Q_i},W^{K_i},W^{V_i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0358em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.2222em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>为第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span>​ 个 attention head 的变换矩阵</p>
<p><strong>接着</strong>, 每个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>Q</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>K</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>V</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(Q_i,K_i,V_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> tuple 都被用于 attention 操作, 得到第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 个 attention head 的特征 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">Z_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, 如(2):</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><msub><mi>Z</mi><mi>i</mi></msub><mo>=</mo><mi>A</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">(</mo><msub><mi>Q</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>K</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>V</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>S</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mfrac><mrow><msub><mi>Q</mi><mi>i</mi></msub><msubsup><mi>K</mi><mi>i</mi><mi>T</mi></msubsup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo stretchy="false">)</mo><msub><mi>V</mi><mi>i</mi></msub></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(2)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">Z_i = Attention(Q_i,K_i,V_i) = Softmax(\frac{Q_iK_i^T}{\sqrt{d_k}})V_i \tag{2}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">A</span><span class="mord mathnormal">tt</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4483em;vertical-align:-0.93em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5183em;"><span style="top:-2.2528em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8572em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8172em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1828em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-2.4413em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2587em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span class="tag"><span class="strut" style="height:2.4483em;vertical-align:-0.93em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">2</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>其中, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">d_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 为queries(keys)的维度</p>
<p>自注意力计算包含矩阵乘法，计算复杂度为<strong>输入长度的二次方</strong></p>
<p><strong>最后</strong>, 将所有 attention head 特征进行拼接, 并对它们进行映射矩阵变换, 如(3):</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>Z</mi><mo>=</mo><mi>C</mi><mi>o</mi><mi>n</mi><mi>c</mi><mi>a</mi><mi>t</mi><mo stretchy="false">(</mo><msub><mi>Z</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>Z</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>Z</mi><mi>h</mi></msub><mo stretchy="false">)</mo><msup><mi>W</mi><mi>O</mi></msup></mrow><annotation encoding="application/x-tex">Z = Concat(Z_1,Z_2,\dots,Z_h)W^O
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1413em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal">c</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">O</span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>其中, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>W</mi><mi>O</mi></msup></mrow><annotation encoding="application/x-tex">W^O</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">O</span></span></span></span></span></span></span></span></span></span></span> 为映射矩阵</p>
</blockquote>
<p>FFN 为 Transformer Block 的另一个重要模块，其被设置在 MHSA 模块之后，其中包含两个线性变换和一个ReLU激活函数（非线性）。</p>
<blockquote>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>F</mi><mi>F</mi><mi>N</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>W</mi><mn>2</mn></msub><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mn>1</mn></msub><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">FFN(X) = W_2\sigma(W_1X)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">FFN</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span></span></p>
</blockquote>
<h3 id="Inference-Process-of-LLMs">Inference Process of LLMs</h3>
<p>目前主流 LLM 采用 <strong>decoder-only</strong> 架构，使用自回归方式生成输出语句，即逐 token 进行输出。在每一次 generation step， 使用过去全部<br>
token 序列（包含原始输入 token 及刚刚生成的 token）作为输入，来生成下一个 token。随着序列长度的增加，生产过程的时间成本会显著增加，为了解决这一问题，一个关键技术，<br>
<strong>Key-Value（KV） Cache</strong> 被提出用于加速生成。</p>
<p>KV Cahce 包含在MHSA模块内，存储和复用前面 token 对应的 key 向量（K）和 value 向量（V）。基于这一项技术，LLM推理过程可以划分为两个阶段：</p>
<ol>
<li>Pre-fill Phase: 计算并存储原始输入 token 的 KV Cache 并生成第一个输出 token。</li>
<li>Decoding Phase：利用 KV Cache 逐个输出 token，并利用新生成 token 的 KV对 KV Cache进行更新。</li>
</ol>
<p><img src="https://static.gumorming.cn/article/68d10a6c60dbdac727aebc773008c884.png" alt="Demonstration of the prefilling stage (a) and decoding stage (b)"></p>
<p><img src="https://static.gumorming.cn/article/494be840790fdf527ef47202cf3e0f6d.png" alt="Illustration of the memory variation through time (latency) during one generation process. Note that we ignore the activation size in this figure for a simplification"></p>
<p>上图展示了提升推理效率的关键指标。</p>
<p>横轴 Latency：</p>
<ul>
<li>在 pre-fill 阶段，将 <code>First Token Latency</code> 记作生成第一个 token 的时间；</li>
<li>在 decoding 阶段，将 <code>Per-output Token Latency</code> 记作生成一个 token 的平均时间；</li>
<li><code>Generation Latency</code> 表示输出整个 token 序列的时间。</li>
</ul>
<p>纵轴 Memory：</p>
<ul>
<li><code>Model Size</code> 表示存储模型权重所需要的内存大小；</li>
<li><code>KV Cache Size</code> 代表存储存储 KV Cache 的内存大小；</li>
<li><code>Peak Memory</code> 代表在生成工程中需要占用的最大内存，其大约为 Model Size 与 KV Cache Size 之和，即模型权重和 KV Cache的内存和。</li>
</ul>
<p>除去延迟和内存中，吞吐量（<code>throughput</code>）也是大模型推理服务系统中的一个广泛使用的指标。<code>token throughput</code>表示每秒生成的token数量，<br>
<code>request throughput</code>表示每秒完成的请求数。</p>
<h3 id="Efficiency-Analysis-大模型推理效率瓶颈分析">Efficiency Analysis: 大模型推理效率瓶颈分析</h3>
<p>大语言模型在实际部署应用中，我们通常关注其<em>时延、吞吐、功耗和存储（latency、throughout、energy and power consumption、storage）</em><br>
，而在大语言模型推理过程中，有三个重要因素会直接影响上述效率指标，分别是<strong>计算开销</strong>（Computational Cost）、<strong>访存开销</strong><br>
（Memory Access Cost）和<strong>存储开销</strong>（Memory Cost）。进一步地，本综述深入分析探究，并总结归纳除出影响上述指标的三个根本因素，分别为：</p>
<ul>
<li><strong>Model Scale</strong>（模型规模）:<br>
主流大语言模型庞大的模型规模会导致巨大的计算量、访存量和存储量。例如，LLaMA-70B模型包括700亿参数，而GPT-3为1750亿参数。在推理过程中，模型大小对计算成本、内存访问成本和内存使用产生了显著影响。</li>
<li><strong>Attention Operation</strong>（注意力计算）: Pre-fill 阶段中，<strong>自注意操作的计算复杂度为输入长度的2次方</strong><br>
，因此随着输入长度的增加，计算成本、内存访问成本和内存使用都会显著增加。</li>
<li><strong>Decoding Approach</strong>（解码方式）: 主流的自回归解码方式导致极低的计算-访存比和硬件利用率，同时动态增长的KV缓存会导致碎片化的内存使用，对访存开销和存储开销带来增长。</li>
</ul>
<p><img src="https://static.gumorming.cn/article/dbdbd3e89b4da134e3659a3294228266.png" alt=""></p>
<h2 id="LLM效率优化技术分类法">LLM效率优化技术分类法</h2>
<p>针对上述影响LLM推理性能的根本因素，文章将LLM效率优化技术划分为三个层次，分别为：</p>
<ul>
<li><strong>Data-level Optimization</strong>: 指通过<strong>优化输入提示词</strong>（Input Compression）或<strong>规划模型输出内容</strong>（Output<br>
Organization）优化推理效率。这类优化技术通常不需要修改模型本身，因此避免了大量的模型训练或微调开销；</li>
<li><strong>Model-level Optimization</strong>: 指通过设计<strong>高效的模型结构</strong>（Efficient Structure Design）或<strong>模型压缩</strong>（Model<br>
Compression）技术优化推理效率。前者通常需要预训练或微调来保留或者恢复模型性能，而后者通常会给模型性能带来<strong>损失</strong>；</li>
<li><strong>System-level Optimization</strong>: 指通过优化<strong>推理引擎</strong>（Inference Engine）或<strong>服务系统</strong>（Serving<br>
System）优化推理效率。推理引擎的优化不需要进行模型训练，服务系统的优化对于模型性能而言是<strong>无损</strong>的。</li>
</ul>
<p><img src="https://static.gumorming.cn/article/ebaf6a3ae460a9ca6e0a675982304c99.png" alt="TAXONOMY"></p>
<h2 id="Data-level-Optimization-数据层面优化">Data-level Optimization 数据层面优化</h2>
<p>Data-level Optimization 可以划分为两大类：<strong>输入压缩(Input Compression)和输出规划（Output Organization）</strong>。</p>
<p>输入压缩技术直接缩短了模型的输入长度来减少推理损失；</p>
<p>输出规划技术通过组织输出内容的结构来实现批量(并行)推理，此方法可以提升硬件利用率和降低模型的生成延迟。</p>
<h3 id="Input-Compression">Input Compression</h3>
<p>在实际利用大语言模型做回答时，通常会在输入提示词中加入一些辅助内容来增强模型的回答质量，例如，上下文学习技术（In-Context<br>
Learning，ICL）提出在输入中加入多个相关的问答例子来教模型如何作答。然而，这些技术不可避免地会增长输入词提示的长度，导致模型推理的开销增大。为了解决该问题，<br>
<strong>输入压缩技术通过直接减小输入的长度来优化模型的推理效率</strong>。</p>
<p>文章将该类技术进一步划分为四个小类：</p>
<ul>
<li><strong>Prompt Pruning（提示词剪枝）</strong>：通常根据设计好的重要度评估指标删除输入提示词中不重要的词块、句子或文段，对被压缩的输入提示词执行压缩。</li>
<li><strong>Prompt Summary（提示词总结）</strong>：通过对输入提示词做文本总结任务，在保证其语义信息相同地前提下缩短输入的长度。</li>
<li><strong>Soft Prompt-based Compression（软提示词压缩）</strong><br>
：通过微调训练的方式得到一个长度较短的软提示词，代替原先的输入提示词或其中固定的一部分内容。其中，软提示词指连续的、可学习的词块序列，可以通过训练的方式学习得到。</li>
<li><strong>Retrieval-Augmented Generation（RAG，检索增强生成）</strong>：通过检索和输入相关的辅助内容，并只将这些相关的内容加入到输入提示词中，来降低原本的输入长度（相比于加入所有辅助内容）。</li>
</ul>
<p><img src="https://static.gumorming.cn/article/fed4cbad790fe8326a10649ebed983ed.png" alt="Input Compression"></p>
<h3 id="Output-Organization">Output Organization</h3>
<p>传统的解码方式是完全串行的，输出规划技术通过组织输出内容的结构，实现（部分的）并行生成来降低端到端的推理延时。</p>
<p>以该领域最早的工作 <strong>Skeleton-of-Thought (SoT)</strong>（ICLR`2023）为例，SoT技术的核心思想是让大语言模型自行规划输出的<strong>并行结构<br>
<strong>，并基于该结构进行</strong>并行生成</strong>，提升硬件利用率，减少端到端生成延时。</p>
<p>具体来说，如下图所示，SoT将大语言模型的生成分为两个阶段：</p>
<ul>
<li>在第一阶段（The Skeleton Stage），SoT通过设计的提示词让大语言模型输出答案的大纲；</li>
<li>在第二阶段（The Point-expanding Stage），SoT让大语言模型基于大纲中的每一个分点并行做扩展，最后将所有分点扩展的答案合并起来。</li>
</ul>
<p><img src="https://static.gumorming.cn/article/40d776776aa75b7877eb642f02c76b40.png" alt="SoT"></p>
<blockquote>
<p>在SoT技术发布后，一些研究工作通过微调大语言模型、前后端协同优化等方式优化输出规划技术，达到了更好的加速比和回答质量之间的权衡。</p>
</blockquote>
<h2 id="Model-level-Optimization">Model-level Optimization</h2>
<p>大模型高效推理的模型级别优化主要集中在模型结构或数据表示的优化上。模型结构优化包括直接设计有效的模型结构、修改原模型和调整推理时间结构。在数据表示优化方面，通常采用模型量化技术。</p>
<p>模型层优化技术可以划分为两大类：<strong>高效结构设计</strong>（Efficient Structure Design）和<strong>模型压缩</strong>（Model<br>
Compression）。前者通常需要将新设计的模型从头进行预训练，而后者通常需要微调恢复精度。</p>
<p><img src="https://static.gumorming.cn/article/d5f7e4720a865cd9ac02633ac47a0d4c.png" alt="Model-level Optimization"></p>
<h3 id="Efficient-Structure-Design">Efficient Structure Design</h3>
<p>目前主流的大语言模型大多采用Transformer架构，从结构上看，参数量占比最多的<strong>前馈神经网络</strong>（FFN）和<strong>平方复杂度的注意力运算</strong><br>
是导致模型推理效率低下的主要原因。</p>
<p>基于此，本文将 Efficient Structure Design 的技术进一步划分为三类：</p>
<ul>
<li>
<p><strong>Efficient FFN Design</strong>: Mixture-of-Experts (MoE, 混合专家)。通过减少激活FFN的数量来降低内存占用。<br>
在基于MoE的Transformers中，多个并行FFN（Expert），与可训练的路由模块一起。在推理过程中，面对不同的输入 token<br>
时，路由模块为每个（组）token 激活特定的专家。</p>
<blockquote>
<p>该领域的研究工作主要关注三个方向：</p>
<ol>
<li>更高效地获取专家FFN的权重或构建更轻量化的专家FFN；</li>
<li>优化路由模型使其分配更加平衡，避免因分配不平衡导致的精度和效率下降；</li>
<li>优化MoE模型的训练方式，使得训练更加稳定。</li>
</ol>
</blockquote>
</li>
<li>
<p><strong>Efficient Attention</strong>: 降低 attention 计算的复杂度</p>
<ul>
<li>
<p><strong>Across attention heads</strong>：</p>
<ul>
<li><strong>Multi/Group-query attention</strong>: 在不同 attention head 之间共享 KV Cache来降低访存开销及内存占用</li>
</ul>
</li>
<li>
<p><strong>Within single attention head</strong>：</p>
<ul>
<li>
<p><strong>Kernel-based attention</strong>：使用核函数，以点乘来近似Softmax运算来降低复杂度。</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>S</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup><mo stretchy="false">)</mo><mi>V</mi><mo>≈</mo><mi>ϕ</mi><mo stretchy="false">(</mo><mi>Q</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>ϕ</mi><mo stretchy="false">(</mo><mi>K</mi><msup><mo stretchy="false">)</mo><mi>T</mi></msup><mi>V</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Softmax(QK^T)V \approx \phi(Q)(\phi(K)^TV)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1413em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1413em;vertical-align:-0.25em;"></span><span class="mord mathnormal">ϕ</span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mclose">)</span><span class="mopen">(</span><span class="mord mathnormal">ϕ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span></span></span></span></span></p>
</li>
<li>
<p><strong>Low-rank attention</strong>: 在执行 attnetion 计算之前，将 K 和 V 矩阵的 token 维度（如 n)压缩到较小的固定长度（如 k)<br>
。该方法基于对 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>×</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">n \times n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span> 矩阵通常表现出低秩特性的观察，使得在 token<br>
维度上压缩是可行的。不需要计算完整的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>×</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">n \times n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span>​ 矩阵，以此降低计算开销。</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>X</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>n</mi><mo>×</mo><mi>d</mi></mrow></msup><mo>→</mo><msup><mi>X</mi><mi mathvariant="normal">‘</mi></msup><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>k</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">X \in \R^{n \times d} \rightarrow X^` \in \R^{k \times d}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8991em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9382em;vertical-align:-0.0391em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">‘</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8991em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span></span></p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Transformer Alternates</strong>:</p>
<ul>
<li><strong>State Space Model</strong>(SSM)</li>
<li><strong>Non-SSM</strong>：
<ul>
<li>Long Convolution</li>
<li>attention-like Linear Operation</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Model-Compression">Model Compression</h3>
<p>满足一些硬性限制（如时延）的同时最大化降低对模型精度的影响</p>
<ul>
<li><strong>Model Quantization</strong>: 模型量化技术通过将模型权重和激活层从 high bit-width 转换为 low bit-width 表示，从而降低LLM显存和计算开销，在<br>
LLM 推理优化领域应用广泛。
<ul>
<li>Post-Training Quantization（PTQ，训练后量化）：指对预训练后的模型直接做量化，不需要重新训练量化后的模型。这类方法对量化后模型的<br>
<strong>精度损失较大</strong>，但因其<strong>不需要额外的模型训练开销</strong>，因此在大语言模型领域应用最为广泛。</li>
<li>Quantization-Aware Training（QAT，量化感知训练）：在模型的训练中加入模型量化过程，并通过训练减小量化带来的精度损失。相比于训练后量化，训练感知量化方法通常具有<br>
<strong>更高的精度</strong>，但其<strong>需要大量的数据和计算量来做模型训练</strong>。因此，目前该子领域的研究主要关注于如何在数据层面和计算量层面降低模型训练带来的开销。</li>
</ul>
</li>
<li><strong>Model Sparsification</strong>：模型稀疏分为 Weight Pruning（权重剪枝）和 Sparse attention（注意力稀疏）。
<ul>
<li>
<p><strong>Weight Pruning</strong>：通过将模型中不重要的权重和对应结构移除，降低模型的计算和存储开销。<br>
<img src="https://static.gumorming.cn/article/9fc9d3101c85ddedb158a31c4a496d3c.png" alt="Weight Pruning"></p>
</li>
<li>
<p><strong>Sparse Attention</strong>：通过减少冗余的注意力计算，来降低预填充阶段的计算开销和解码阶段中KV cache带来存储和访存开销。</p>
</li>
</ul>
</li>
<li><strong>Structure Optimization</strong>: 结构优化，通过修改模型的架构或结构来达到更好的<strong>精度-效率</strong>之间的权衡。在该领域有两类代表性的技术：
<ul>
<li><strong>Neural Architecture Search</strong>：<br>
神经网络架构搜索，自动化地搜索出最优的模型架构。然而，这类方法目前只在中等规模的语言模型上得到应用，在大语言模型上还未获得实际的优化效果，原因是该技术通常需要在搜索过程中对采样到的架构进行训练评估，对大模型来说需要花费巨大的训练开销。</li>
<li><strong>Low Rank Factorization</strong>：低秩分解，将一个大的权重矩阵近似分解成两个低质小矩阵的乘积，通过该技术，可以降低大语言模型权重的存储开销和访存开销。</li>
</ul>
</li>
<li><strong>Knowledge Distillation</strong>: 知识蒸馏，指用一个大模型（教师模型）来辅助训练一个小模型（学生模型），从而将大模型的知识传递给小模型，通过小模型更小的开销达到相似的精度效果。
<ul>
<li><strong>White-box</strong>: 可以获得教师模型的架构和权重，因此可以利用更多的信息（例如特征、输出概率等）训练学生模型</li>
<li><strong>Black-box</strong>: 多针对基于API接口访问的大模型，这类模型的架构和权重无法获取，因此仅能通过构造数据来训练学生模型。</li>
</ul>
</li>
<li><strong>Dynamic Inference</strong>：动态推理，在推理过程中，基于输入数据的不同，动态决定最合适的模型子结构。涉及到 <strong>early exiting</strong> 技术。</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://GuMorming.github.io">GuMorming</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://gumorming.github.io/article/b9645bc9/">https://gumorming.github.io/article/b9645bc9/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noreferrer" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://gumorming.github.io" target="_blank">GuMorming</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Survey/">Survey</a><a class="post-meta__tags" href="/tags/LLM/">LLM</a><a class="post-meta__tags" href="/tags/Inference/">Inference</a></div><div class="post_share"><div class="social-share" data-image="https://static.gumorming.cn/article/085dcf98b9e5a23d8ac570261a77058b.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/reward/Alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/reward/Alipay.jpg" alt="支付宝（Alipay）"/></a><div class="post-qr-code-desc">支付宝（Alipay）</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/article/78c76c8c/" title="[Paper Reading] LoongServe Efficiently Serving Long-context Large Language Models with Elastic Sequence Parallelism"><img class="cover" src="https://static.gumorming.cn/article/eeab44471e5008281510a647da82a2c3.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">[Paper Reading] LoongServe Efficiently Serving Long-context Large Language Models with Elastic Sequence Parallelism</div></div></a></div><div class="next-post pull-right"><a href="/article/74222011/" title="[Paper Reading] DistServe: Disaggregating Prefill and Decoding for Goodput-optimized Large Language Model Serving"><img class="cover" src="https://static.gumorming.cn/article/f03cb69a21a4dab663de72c03b14309b.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">[Paper Reading] DistServe: Disaggregating Prefill and Decoding for Goodput-optimized Large Language Model Serving</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/article/4e5a6680/" title="[Paper Reading] ChunkAttention: Efficient Self-Attention with Prefix-Aware KV Cache and Two-Phase Partition"><img class="cover" src="https://static.gumorming.cn/article/0dd8f9e32cc0427f6f698a57f1b98e47.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-23</div><div class="title">[Paper Reading] ChunkAttention: Efficient Self-Attention with Prefix-Aware KV Cache and Two-Phase Partition</div></div></a></div><div><a href="/article/74222011/" title="[Paper Reading] DistServe: Disaggregating Prefill and Decoding for Goodput-optimized Large Language Model Serving"><img class="cover" src="https://static.gumorming.cn/article/f03cb69a21a4dab663de72c03b14309b.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-07-26</div><div class="title">[Paper Reading] DistServe: Disaggregating Prefill and Decoding for Goodput-optimized Large Language Model Serving</div></div></a></div><div><a href="/article/c6c0812d/" title="[Paper Reading] InfiniGen: Efficient Generative Inference of Large Language Models with Dynamic KV Cache Management"><img class="cover" src="https://static.gumorming.cn/article/1a15ab3bf06f7c29905af9696b009402.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-09-06</div><div class="title">[Paper Reading] InfiniGen: Efficient Generative Inference of Large Language Models with Dynamic KV Cache Management</div></div></a></div><div><a href="/article/3109dcd2/" title="[Paper Reading] FlexGen: High-Throughput Generative Inference of Large Language Models with a Single GPU"><img class="cover" src="https://static.gumorming.cn/article/5eac705b9046068c046afc2b631c1cdd.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-15</div><div class="title">[Paper Reading] FlexGen: High-Throughput Generative Inference of Large Language Models with a Single GPU</div></div></a></div><div><a href="/article/c1bfc42f/" title="[Paper Reading] Infinite-LLM: Efficient LLM Service for Long Context with DistAttention and Distributed KV Cache"><img class="cover" src="https://static.gumorming.cn/article/d849c6150890acfbd7a877fad6aca0ea.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-07-02</div><div class="title">[Paper Reading] Infinite-LLM: Efficient LLM Service for Long Context with DistAttention and Distributed KV Cache</div></div></a></div><div><a href="/article/6d0559f/" title="[Paper Reading] KVQuant: Towards 10 Million Context Length LLM Inference with KV Cache Quantization"><img class="cover" src="https://static.gumorming.cn/article/a9c51b9507abd7fa2cbf1971d90df550.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-16</div><div class="title">[Paper Reading] KVQuant: Towards 10 Million Context Length LLM Inference with KV Cache Quantization</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#PRELIMINARIES"><span class="toc-number">1.</span> <span class="toc-text">PRELIMINARIES</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Transformer-Styles-LLMs"><span class="toc-number">1.1.</span> <span class="toc-text">Transformer-Styles LLMs</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Inference-Process-of-LLMs"><span class="toc-number">1.2.</span> <span class="toc-text">Inference Process of LLMs</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Efficiency-Analysis-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E6%95%88%E7%8E%87%E7%93%B6%E9%A2%88%E5%88%86%E6%9E%90"><span class="toc-number">1.3.</span> <span class="toc-text">Efficiency Analysis: 大模型推理效率瓶颈分析</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LLM%E6%95%88%E7%8E%87%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF%E5%88%86%E7%B1%BB%E6%B3%95"><span class="toc-number">2.</span> <span class="toc-text">LLM效率优化技术分类法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Data-level-Optimization-%E6%95%B0%E6%8D%AE%E5%B1%82%E9%9D%A2%E4%BC%98%E5%8C%96"><span class="toc-number">3.</span> <span class="toc-text">Data-level Optimization 数据层面优化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Input-Compression"><span class="toc-number">3.1.</span> <span class="toc-text">Input Compression</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Output-Organization"><span class="toc-number">3.2.</span> <span class="toc-text">Output Organization</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Model-level-Optimization"><span class="toc-number">4.</span> <span class="toc-text">Model-level Optimization</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Efficient-Structure-Design"><span class="toc-number">4.1.</span> <span class="toc-text">Efficient Structure Design</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Model-Compression"><span class="toc-number">4.2.</span> <span class="toc-text">Model Compression</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2024 By GuMorming</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text"><img src="https://static.gumorming.cn/beiantubiao.png" class="w-full" alt="" style="width: 16px;"> &nbsp; <a  href="https://beian.mps.gov.cn/#/query/webSearch?code=13040202001022" rel="noreferrer" target="_blank"> 冀公网安备13040202001022 &nbsp; &nbsp;</a><a href="https://beian.miit.gov.cn/" rel="external nofollow noreferrer" target="_blank"> 冀ICP备2024065263号</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@5.2.0/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.16/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"></div><script src="/assets/js/busuanzi.pure.mini.js"></script><script async data-pjax src="/assets/js/gumorming.js"></script><div class="aplayer no-destroy" data-id="60198" data-server="netease" data-type="playlist" data-fixed="true" data-autoplay="true"> </div><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener
  btf.removeGlobalFnEvent('pjax')
  btf.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>